vocab:
    vocab_size: 10000
    pad_id: 0
    unk_id: 1
    bos_id: 2
    eos_id: 3
    pad_token: "[PAD]"
    unk_token: "[UNK]"
    bos_token: "[BOS]"
    eos_token: "[EOS]"


model:
    emb_dim: 256
    direction: 2    
    hidden_dim: 512
    n_layers: 2
    dropout_ratio: 0.5
    max_len: 512


train:
    n_epochs: 10
    batch_size: 32
    lr: 0.00
    early_stop: 1
    patience: 3
    clip: 1
    iters_to_accumulate: 405